# -*- coding: utf-8 -*-
"""Hierarchical_Clustering

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/110L64nuIVPt3R8bZHEaXiWBjkhPeo-Yq
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf
import scipy.cluster
import numpy as np

# import hierarchical clustering libraries
import scipy.cluster.hierarchy as sch 
from sklearn.cluster import AgglomerativeClustering
import seaborn as sn

from google.colab import files
upload = files.upload()

uni = pd.read_csv("Copy of Universities.csv")

# Normalization function # use sklearn library norm
def norm_func(i):
  x = (i-i.min())/(i.max()-i.min())
  return x

# Normalized data frame (considering the numerical part of data)
df_norm = norm_func(uni.iloc[:,1:])

df_norm

# create dendrogram
#dendrogram = sch.dendrogram(sch.linkage(df_norm, method='complete'))
dendrogram = sch.dendrogram(sch.linkage(df_norm, method='single'))

# create clusters
hc = AgglomerativeClustering(n_clusters=5, affinity = 'euclidean',linkage = 'complete')

hc.fit(df_norm)
# hc.predict(df_norm)

# save clusters for chart
y_hc = hc.fit_predict(df_norm)
# Clusters=pd.DataFrame(y_hc,columns=['Clusters'])

y_hc

uni['h_clusterid'] = y_hc

uni.head()

univ1=uni.sort_values("h_clusterid")
univ1.iloc[:,[0,-1]]

